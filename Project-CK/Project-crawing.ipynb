{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://danso.org/viet-nam/#bieu-do\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Mar 28 23:57:46 2019\n",
    "\n",
    "@author: Chuong Pham\n",
    "\"\"\"\n",
    "\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "\n",
    "# specify the url\n",
    "urlpage =  'https://danso.org/viet-nam/#bieu-do' \n",
    "print(urlpage)\n",
    "# query the website and return the html to the variable 'page'\n",
    "page = urllib.request.urlopen(urlpage)\n",
    "# parse the html using beautiful soup and store in variable 'soup'\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "main = soup.find('table', attrs={'id': 'nam'}).find('tbody')\n",
    "results = main.find_all('tr')\n",
    "\n",
    "rows = []\n",
    "rows.append(['Nam', 'DanSo', 'PTThayDoi','ThayDoi','DiCu', 'TuoiTB', 'TiLeSinh', 'MatDo','PTDanThanhThi','DanThanhThi','PTTheGioi','TheGioi','Hang'])\n",
    "\n",
    "for result in results:\n",
    "    one_data = result.find_all('td')\n",
    "    Nam = one_data[0].getText()\n",
    "    DanSo =one_data[1].getText()\n",
    "    PTThayDoi =one_data[2].getText()\n",
    "    ThayDoi = one_data[3].getText()\n",
    "    DiCu = one_data[4].getText()\n",
    "    TuoiTB =one_data[5].getText()\n",
    "    TiLeSinh =one_data[6].getText()\n",
    "    MatDo =one_data[7].getText()\n",
    "    PTDanThanhThi =one_data[8].getText()\n",
    "    DanThanhThi =one_data[9].getText()\n",
    "    PTTheGioi = one_data[10].getText()\n",
    "    TheGioi = one_data[11].getText()\n",
    "    Hang = one_data[12].getText()\n",
    "    \n",
    "    rows.append([Nam, DanSo, PTThayDoi,ThayDoi, DiCu, TuoiTB, TiLeSinh, MatDo,PTDanThanhThi,DanThanhThi,PTTheGioi,TheGioi,Hang])\n",
    "    \n",
    "with open('danso.csv','w', encoding='utf-8', newline='') as f_output:\n",
    "    csv_output = csv.writer(f_output)\n",
    "    csv_output.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://weather.com/vi-VN/weather/tenday/l/VMXX0006:1:VM\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Mar 28 23:57:46 2019\n",
    "\n",
    "@author: Chuong Pham\n",
    "\"\"\"\n",
    "\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "\n",
    "# specify the url\n",
    "urlpage =  'https://weather.com/vi-VN/weather/tenday/l/VMXX0006:1:VM' \n",
    "print(urlpage)\n",
    "# query the website and return the html to the variable 'page'\n",
    "page = urllib.request.urlopen(urlpage)\n",
    "# parse the html using beautiful soup and store in variable 'soup'\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "main = soup.find('table', attrs={'class': 'twc-table'}).find('tbody')\n",
    "results = main.find_all('tr')\n",
    "\n",
    "rows = []\n",
    "rows.append(['Ngay', 'MoTa', 'Mintemp','Maxtemp','LuongMua','VGio', 'DoAm'])\n",
    "\n",
    "for result in results:\n",
    "    data = result.find_all('td')\n",
    "    Ngay = result.find('span', attrs={'class': 'day-detail clearfix'}).getText().strip()\n",
    "    MoTa = result.find('td', attrs={'class': 'description'}).getText().strip()\n",
    "    temp = result.find('td', attrs={'class': 'temp'}).getText().strip()\n",
    "    Temp = temp.split('Â°')\n",
    "    Maxtemp = Temp[0]\n",
    "    Mintemp = Temp[1]\n",
    "    LuongMua = result.find('td' , attrs={'class': 'precip'}).getText().strip()\n",
    "    VGio = result.find('td' , attrs={'class': 'wind'}).find('span').getText().strip()\n",
    "    DoAm = result.find('td' , attrs={'class': 'humidity'}).find('span').getText().strip()\n",
    "    rows.append([Ngay, MoTa, Mintemp,Maxtemp,LuongMua, VGio, DoAm])\n",
    "    \n",
    "with open('thoitiet.csv','w', encoding='utf-8', newline='') as f_output:\n",
    "    csv_output = csv.writer(f_output)\n",
    "    csv_output.writerows(rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
